---

title: "Haciendo Big Data a League of Legends"
author: "Jorge de Andrés"
date: "16 de enero de 2019"
output:
  html_document: default
  word_document: default
  pdf_document: default
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Limpiamos environment:

```{r limpiar_environment}

rm(list=ls())

```


Importamos los paquetes necesarios:

```{r paquetes, echo=T, results="hide"}

#install.packages("knitr")
#install.packages("dplyr")
#install.packages("pryr")
#install.packages("corrplot")
#install.packages("rjson")
#install.packages("plyr")
#install.packages("wordcloud")
#install.packages("ggplot2")
#install.packages("hexbin")
#install.packages("RColorBrewer")
#install.packages("FactoMineR")
#devtools::install_github("kassambara/factoextra")
#install.packages("factoextra")
#install.packages("arules")
#install.packages("arulesViz")
#install.packages("fastDummies")
#install.packages("caret")
#install.packages("nnet")
#install.packages("gmodels")
#install.packages("class")
#install.packages("randomforest")
#install.packages("e1071")
#install.packages("aplpack")
#install.packages("cluster")
#install.packages("fpc")
#install.packages("purrr")
#install.packages("RWeka")

library("corrplot")
library("dplyr")
library("pryr")
library("rjson")
library("plyr")
library("wordcloud")
library("ggplot2")
library("hexbin")
library("RColorBrewer")
library("FactoMineR")
library("factoextra")
require("arulesViz")
require("arules")
library("Matrix")
library("fastDummies")
library("caret")
library("nnet")
library("gmodels")
library("class")
library("randomForest")
library("e1071")
library("aplpack")
library("cluster")
library("fpc")
library("purrr")
library("RWeka")
library("data.table")


```


Lo primero que voy a hacer es importar todos los datasets:

```{r import_data_csv}

data.games <- read.csv("../data/games.csv")
data.champs <- read.csv("../data/champs.csv")

```

Hemos importado varios CSV que harán las tablas de la base de datos.

Importamos los json:

```{r import_data_json}

lista.championInfo <- fromJSON(file = "../data/champion_info.json")
lista.championInfo2 <- fromJSON(file="../data/champion_info_2.json")
lista.summonerSpell <- fromJSON(file="../data/summoner_spell_info.json")

```



Tamaño de mis datasets...

```{r tamaño_datasets}

print( paste0("El tamaño de la tabla de games es de: "))
object_size(data.games)

```
Esto me devuelve las filas que tengan NA:

```{r searching_for_NA}

data.games[!complete.cases(data.games),]

```

Como podemos ver, no tenemos filas con NA.

Como voy a ir haciendo "pequeños proyectos" para ir sacando conocimiento por ahora no voy a fusionar ninguna tabla de primeras porque no se lo que voy a necesitar.
Según se vayan planteando los interrogantes iré jugando con las tablas para conseguir los objetivos

# Análisis Exploratorio

Empezamos por el análisis exploratorio de los datos.
Para ello, vamos intentar ver conclusiones sobre los mismos:

```{r summaries}

print("Resumen de data.games")
summary(data.games) # Las únicas columnas interesantes son la 5 y la 6


```

Una vez que tenemos los estadísticos básicos principales, vamos a limpiar algunos datasets de variables que no necesitamos para poder hacer análisis de variables con su correlación y similares...

```{r limpieza_Variables_no_queridas_correlacion}

# Ahora voy a hacer una tabla de games especial solo con las variables de las que calcularemos las correlaciones
# Game ID es una variable que no necesito para nada, por lo que la voy a eliminar:

data.games.corr <- data.games[, c(-1, -4)]
#head(data.games.corr)
data.games.corr <- data.games.corr[, -10:-24]
#head(data.games.corr)
data.games.corr <- data.games.corr[, -15:-34]
#head(data.games.corr)
data.games.corr <- data.games.corr[, -20:-24]

```

## Correlation Plots

Lo primero que voy a hacer son los correlation plot de cada una de las tablas. Vamos a ver qué relaciones tenemos entre los datos, para poder ver si podemos ir sacando algunas conclusiones...

```{r calculo_correlacion_games}

res.games <- cor(data.games.corr, method = "spearman")
options(width = 100)
res.games.round <- round(res.games, 2)

```

El primer gráfico que muestro es entre la duración de las partidas y la temporada en la que se está jugando:

```{r grafico_correlaciones_variables_matches}

corrplot(res.games.round, method="circle", type = "upper")

```

Exportamos el corrplot a PDF para tenerlo vectorial y poderlo ver mejor...

```{r export_PDF_corrplot}

pdf("../imagenes/corrplot.pdf")
corrplot(res.games.round, method="circle", type = "upper")
dev.off


```


Podemos apreciar las siguientes correlaciones sobre destruir torres:

+ Destruir más torres tiene una relación directa con destruir inhibidores
+ Destruir más torres tiene una cierta relación directa con matar dragones
+ Destruir más torres tiene una cierta relación inversa con que el equipo contrario destruya tus torres
+ Destruir más torres tiene uan cierta relación con que el equipo contrario mate menos dragones

Respecto a ganar, obtenemos las siguientes correlaciones:

+ Muchas veces, quien destruye el primer inhibidor es el equipo que acaba ganando la partida
+ Un aumento en que el equipo 1 destruya más torres tiene que ver con que tengan más posibilidades de victoria. Esto se da con una relación inversa, ya que la victoria del equipo 1 se marca con un 1, la del 2 con un dos, y el aumento de towerkills de t1 implica una bajada en win (1 en vez de dos)
+ Lo mismi pasa con la cantidad de inhibidores destruidos, donde es también una relación muy fuerte la que hay.
+ Con el equipo 2 pasa lo mismo, lo que pasa es que, por lo explicado anteriormente, en este caso se muestra como relación direta, y de este modo podemos ver las mismas correlaciones de una parte que de otra.

Respecto a dragones, podemos ver:

+ Es más importante para el equipo 2 hacerse el primer dragón de cara a hacerse más que el que el equipo 1 haga el mismo.

Finalmente, respecto a el momento de la creación de la partida, podemos observar:

+ No tiene ninguna relación el paso del tiempo cno el aumento o disminución de ninguna de las variables.


## PCA

Vamos a hacer ahora un análisis de las componentes principales:
Para los cálculos, uso la matriz con el centrado y escalado ya hechos

```{r PCA_Calculations}

resultado.pca <- PCA(data.games.corr, graph = FALSE)

#Con la siguiente línea podemos ver que podemos hacer con esto calculado
print(resultado.pca)

```
Nos interesa ver los eigenvalues, que son los que presentarán la cantidad de varianza que aportan las variables:

```{r table_eigenvalues_PCA}

eigenvalues.PCA <- resultado.pca$eig
eigenvalues.PCA

```

Como podemos ver, tenemos 19 componentes principales (una por cada dimensión), y vemos que solo con 10 variables ya tenemos un 90% de explicación.
Además, de cara a la representación en dos dimensiones, podemos ver que con solo las dos variables con más varianza tenemos una explicación del 47,7%.

Ahora, para completar este apartado de PCA, lo que voy a hacer es sacar la gráfica de la varianza acumulada con los valores anteriores:

```{r PCA_eigenvalues_graph}

plotPCA <- fviz_screeplot(resultado.pca, ncp=19, main="Barplot de explicación de varianza", ylab="Porcentaje de explicación", xlab="Dimensión")
plot(plotPCA)

```

Ahora voy a sacar un "Factor Map" de las variables. Esto lo puedo hacer gracias a las coordenadas que me da una de las variables tras hacer el PCA.
Así, voy primero a ver la tabla y luego voy a sacar el mapa:

```{r PCA_Coordinates}

head(resultado.pca$var$coord)

```

Como se puede ver, me está poniendo mis 24 variables en 5 dimensiones, con unas coordenadas concretas. Ahora, lo que voy a hacer, es representarlo.
Con esta representación podré sacar algunas conclusiones:

```{r PCA_Coordinates_Graph}

fviz_pca_var(resultado.pca)

```

Es interesante ver como no hay nada que vaya en la misma dirección que la victoria. T1 tiene que ser interpretado de una manera en espejo respecto al eje de las Y, y vemos como muchísimas variables como el heraldo, first blood, número de dragones... todas tienen más o menos la misma importancia de cara a conseguir la victoria.

Vemos como la duración del juego forma un ángulo de 90 grados con la victoria, lo cual significa que no tiene nada que ver.

Ahora vamos a ver en un mapa, sobre las dos componentes principales, todas las partidas:

```{r plot_coordendas_individuos}

fviz_pca_ind(resultado.pca)

```

Exportamos estos gráficos del PCA de los individuos...

```{r export_PCA_individuos}

pdf("../imagenes/PCAIndividuos.pdf")

plot(plotPCA)
fviz_pca_var(resultado.pca)
fviz_pca_ind(resultado.pca)

dev.off

```


Como se puede apreciar en este gráfico también, prácticamente todas las partidas forman un gran cluster (representado sobre las dos componentes con más variabilidad), y esto nos demuestra que no hay demasiada varianza entre unas partidas y otras. En otras palabras, no podemos distinguir fácilmente varios tipos de partidas, todas son parecidas y no hay diferencias suficientes para clasificar en grupos, más que en uno grande.


Para analizar la variabilidad de algunas partidas, vamos a verlo mediante el método de las caras de Chernoff:

```{r chernoff}

muestra_partidas <- data.games[1:16, 27:31]
muestra_partidas <- cbind(muestra_partidas, data.games[1:16, 52:56])
faces(muestra_partidas[1:10], face.type=1,labels=data.games[1:16, 5], main = "Diferencias entre partidas", scale = TRUE, cex = 1.5)

```

Lo exportamos a PDF para tener más calidad al pasarlo a vectorial...

```{r export_PDF_chernoff}

pdf("../imagenes/chernoff partidas.pdf")
faces(muestra_partidas[1:10], face.type=1,labels=data.games[1:16, 5], main = "Diferencias entre partidas", scale = TRUE, cex = 1.5)
dev.off

```


Como podemos ver, hay diferencias entre las partidas ganadas por el equipo 1 (caras en general más grandes y geométricas, pelo hacia arriba) y las del equipo 2 (pelo hacia abajo y amarillo, cara roja en la mitad, cara redondeada...)


## Preguntas

Ahora que tenemos las correlaciones vistas, podemos pasar a hacernos preguntas.

### ¿Campeón más baneado por temporada?

Uno de los elementos que más se tienen en cuenta a la hora de analizar el League of Legends en los e-sports es el campeón más baneado por temporada o campeonato. Esto es porque desde Riot Games hacen cambios a las habilidades y fuerza de los personajes, de tal manera que algunas veces algunos campeones son demasiado fuertes y se pueden bloquear al inicio de la partida. 
Vamos a ver cuáles han sido:

Para analizar esto, contaré la cantidad de ocurrencias y veré, en estas más de 50.000 partidas, cual es el campeón más temido entre los jugadores, tras sustiruir por los nombres.

```{r preparation_bans}

# Lo que voy a hacer es contar por columnas, y luego sumo todas las columnas que he contado. Así obtengo el recuento final

# TEAM 1

cont.bans.t1.1 <- ddply(data.games,.(t1_ban1),nrow)
cont.bans.t1.1 <- cont.bans.t1.1[order(cont.bans.t1.1$V1, decreasing = TRUE), ]
cont.bans.t1.2 <- ddply(data.games,.(t1_ban2),nrow)
cont.bans.t1.2 <- cont.bans.t1.2[order(cont.bans.t1.2$V1, decreasing = TRUE), ]
cont.bans.t1.3 <- ddply(data.games,.(t1_ban3),nrow)
cont.bans.t1.3 <- cont.bans.t1.3[order(cont.bans.t1.3$V1, decreasing = TRUE), ]
cont.bans.t1.4 <- ddply(data.games,.(t1_ban4),nrow)
cont.bans.t1.4 <- cont.bans.t1.4[order(cont.bans.t1.4$V1, decreasing = TRUE), ]
cont.bans.t1.5 <- ddply(data.games,.(t1_ban5),nrow)
cont.bans.t1.5 <- cont.bans.t1.5[order(cont.bans.t1.5$V1, decreasing = TRUE), ]

# TEAM 2

cont.bans.t2.1 <- ddply(data.games,.(t2_ban1),nrow)
cont.bans.t2.1 <- cont.bans.t2.1[order(cont.bans.t2.1$V1, decreasing = TRUE), ]
cont.bans.t2.2 <- ddply(data.games,.(t2_ban2),nrow)
cont.bans.t2.2 <- cont.bans.t2.2[order(cont.bans.t2.2$V1, decreasing = TRUE), ]
cont.bans.t2.3 <- ddply(data.games,.(t2_ban3),nrow)
cont.bans.t2.3 <- cont.bans.t2.3[order(cont.bans.t2.3$V1, decreasing = TRUE), ]
cont.bans.t2.4 <- ddply(data.games,.(t2_ban4),nrow)
cont.bans.t2.4 <- cont.bans.t2.4[order(cont.bans.t2.4$V1, decreasing = TRUE), ]
cont.bans.t2.5 <- ddply(data.games,.(t2_ban5),nrow)
cont.bans.t2.5 <- cont.bans.t2.5[order(cont.bans.t2.5$V1, decreasing = TRUE), ]

# Ahora lo que tengo que hacer es sumar todas estas columnas de V1 según el valor de name...

df.bans <- left_join(cont.bans.t1.1, cont.bans.t1.2, by =c("t1_ban1" = "t1_ban2"))
df.bans <- left_join(df.bans, cont.bans.t1.3, by =c("t1_ban1" = "t1_ban3"))
df.bans <- left_join(df.bans, cont.bans.t1.4, by =c("t1_ban1" = "t1_ban4"))
df.bans <- left_join(df.bans, cont.bans.t1.5, by =c("t1_ban1" = "t1_ban5"))

df.bans <- left_join(df.bans, cont.bans.t2.1, by =c("t1_ban1" = "t2_ban1"))
df.bans <- left_join(df.bans, cont.bans.t2.2, by =c("t1_ban1" = "t2_ban2"))
df.bans <- left_join(df.bans, cont.bans.t2.3, by =c("t1_ban1" = "t2_ban3"))
df.bans <- left_join(df.bans, cont.bans.t2.4, by =c("t1_ban1" = "t2_ban4"))
df.bans <- left_join(df.bans, cont.bans.t2.5, by =c("t1_ban1" = "t2_ban5"))

df.bans$total <- rowSums( df.bans[,2:11] )

remove(cont.bans.t1.1)
remove(cont.bans.t1.2)
remove(cont.bans.t1.3)
remove(cont.bans.t1.4)
remove(cont.bans.t1.5)
remove(cont.bans.t2.1)
remove(cont.bans.t2.2)
remove(cont.bans.t2.3)
remove(cont.bans.t2.4)
remove(cont.bans.t2.5)

df.bans <- df.bans[order(df.bans$total, decreasing = TRUE), ]
df.bans <- df.bans[, -2:-11]
head(df.bans)

# Finalmente, junto con la tabla de data.champs para ponerles nombre...

df.bans <- left_join(df.bans, data.champs, by=c("t1_ban1" = "id"))
df.bans <- df.bans[, -1]
head(df.bans)


```
Ahora que tenemos todos los bans contados, es hora de hacer un wordcloud para poder verlo visualmente:

```{r wordcloud_bans}

set.seed(9999) # Para el mantenimiento del mismo patrón

wordcloud(words = df.bans$name, freq = df.bans$total, min.freq = 1, random.order=FALSE, 
          rot.per=0.5, colors=c("Orange","Purple","Pink", "Red", "Yellow", "Green", "Blue", "Black"))

# Ratio del más baneado

print("El porcentaje de baneo a Yasuo es de: ")
ratio.ban.yasuo <- df.bans$total[1]/sum(df.bans$total)
print(ratio.ban.yasuo)

```

Exportamos el wordcloud a PDF para tenerlo vectorial...

```{r export_PDF_wordcloud_bans}

set.seed(9999) # Para el mantenimiento del mismo patrón

wordcloud(words = df.bans$name, freq = df.bans$total, min.freq = 1, random.order=FALSE, 
          rot.per=0.5, colors=c("Orange","Purple","Pink", "Red", "Yellow", "Green", "Blue", "Black"))

dev.off

```


Pregunta respondida.

### ¿Matar un mayor número de dragones aumenta las posibilidades de victoria?

Esto lo vamos a responder para el equipo 1 y para el equipo 2, de tal manera que podamos ver si tiene más influencia en uno u en otro.

Para esto, necesito la cantidad de dragones matados por el equipo que venció y por el equipo que perdió, y esos datos los tengo en el dataset de data.games.

```{r get_dataset_dragons_win}

data.dragons.win <- cbind(data.games$t1_dragonKills, data.games$t2_dragonKills, data.games$winner)
colnames(data.dragons.win) <- c("KillsT1", "KillsT2", "Win")
head(data.dragons.win)

```

Primero vamos a estudiar la correlación. La hemos visto anteriormente, pero vamos a hacerlo ahora en especial de esta tabla para verlo de una manera más grande:


```{r calculo_correlacion_dragons_win}

res.dragons.win <- cor(data.dragons.win, method = "spearman")
options(width = 100)
res.dragons.win.round <- round(res.dragons.win, 2)

```

```{r grafico_correlaciones_dragons_win}

corrplot(res.dragons.win.round, method="square", type = "upper", tl.srt = 0.7)

```

Lo exportamos a PDF para poderlo ver con mayor calidad...

```{r export_PDF_correlaciones_Drakes}

pdf("../imagenes/DrakesCorr.pdf")

corrplot(res.dragons.win.round, method="square", type = "upper", tl.srt = 0.7)

dev.off

```


Como podemos ver, tenemos una correlación de aproximadamente el 50% entre el aumento del número de dragones matados y conseguir la victoria.


#### Equipo 1

Vamos a ver el número de dragones matados por el equipo 1 respecto a la victoria:

```{r mosaicplot_dragons_t1}

mosaicplot(table(data.dragons.win[, 1], data.dragons.win[, 3]), main='Winrate por dragones matados, Equipo 1', shade=TRUE)

```

Como podemos ver, el equipo 1, si no mata a ningún dragón, tiene serias posibilidades de no ser el equipo que gane.
Conforme va matando dragones, aumenta la posibilidad, especialmente con el paso de 1 a 2 dragones, donde se planta con una mayor parte de las posibilidades.

A partir de los 3 dragones matados, el hecho de matar más no tiene prácticamente influencia en el resultado final.

#### Equipo 2

Procedemos igual con el equipo 2:

```{r mosaicplot_dragons_t2}

mosaicplot(table(data.dragons.win[, 2], data.dragons.win[, 3]), main='Winrate por dragones matados, Equipo 2', shade=TRUE)

```

Exportamos los MosaicPlot a PDF para tenerlos vectoriales...

```{r export_PDF_mosaicPlot_drakes}

pdf("../imagenes/Drakes MosaicPlot.pdf")

mosaicplot(table(data.dragons.win[, 1], data.dragons.win[, 3]), main='Winrate por dragones matados, Equipo 1', shade=TRUE)
mosaicplot(table(data.dragons.win[, 2], data.dragons.win[, 3]), main='Winrate por dragones matados, Equipo 2', shade=TRUE)

dev.off

```


Como se puede observar, las distribuciones son prácticamente similares, solo que en espejo como es normal.


### ¿Cuales son los campeones más escogidos?

Sabemos que Yasuo es el campeón más baneado, con un 6% de banrate.
Ahora me pregunto cual es el campeón más escogido para jugar.

Para ello, tenemos que seguir la misma metodología que en la parte de los baneos:

```{r preparation_picks}

# Lo que voy a hacer es contar por columnas, y luego sumo todas las columnas que he contado. Así obtengo el recuento final

# TEAM 1

cont.picks.t1.1 <- ddply(data.games,.(t1_champ1id),nrow)
cont.picks.t1.1 <- cont.picks.t1.1[order(cont.picks.t1.1$V1, decreasing = TRUE), ]
cont.picks.t1.2 <- ddply(data.games,.(t1_champ2id),nrow)
cont.picks.t1.2 <- cont.picks.t1.2[order(cont.picks.t1.2$V1, decreasing = TRUE), ]
cont.picks.t1.3 <- ddply(data.games,.(t1_champ3id),nrow)
cont.picks.t1.3 <- cont.picks.t1.3[order(cont.picks.t1.3$V1, decreasing = TRUE), ]
cont.picks.t1.4 <- ddply(data.games,.(t1_champ4id),nrow)
cont.picks.t1.4 <- cont.picks.t1.4[order(cont.picks.t1.4$V1, decreasing = TRUE), ]
cont.picks.t1.5 <- ddply(data.games,.(t1_champ5id),nrow)
cont.picks.t1.5 <- cont.picks.t1.5[order(cont.picks.t1.5$V1, decreasing = TRUE), ]

# TEAM 2

cont.picks.t2.1 <- ddply(data.games,.(t2_champ1id),nrow)
cont.picks.t2.1 <- cont.picks.t2.1[order(cont.picks.t2.1$V1, decreasing = TRUE), ]
cont.picks.t2.2 <- ddply(data.games,.(t2_champ2id),nrow)
cont.picks.t2.2 <- cont.picks.t2.2[order(cont.picks.t2.2$V1, decreasing = TRUE), ]
cont.picks.t2.3 <- ddply(data.games,.(t2_champ3id),nrow)
cont.picks.t2.3 <- cont.picks.t2.3[order(cont.picks.t2.3$V1, decreasing = TRUE), ]
cont.picks.t2.4 <- ddply(data.games,.(t2_champ4id),nrow)
cont.picks.t2.4 <- cont.picks.t2.4[order(cont.picks.t2.4$V1, decreasing = TRUE), ]
cont.picks.t2.5 <- ddply(data.games,.(t2_champ5id),nrow)
cont.picks.t2.5 <- cont.picks.t2.5[order(cont.picks.t2.5$V1, decreasing = TRUE), ]

# Ahora lo que tengo que hacer es sumar todas estas columnas de V1 según el valor de name...

df.picks <- left_join(cont.picks.t1.1, cont.picks.t1.2, by =c("t1_champ1id" = "t1_champ2id"))
df.picks <- left_join(df.picks, cont.picks.t1.3, by =c("t1_champ1id" = "t1_champ3id"))
df.picks <- left_join(df.picks, cont.picks.t1.4, by =c("t1_champ1id" = "t1_champ4id"))
df.picks <- left_join(df.picks, cont.picks.t1.5, by =c("t1_champ1id" = "t1_champ5id"))

df.picks <- left_join(df.picks, cont.picks.t2.1, by =c("t1_champ1id" = "t2_champ1id"))
df.picks <- left_join(df.picks, cont.picks.t2.2, by =c("t1_champ1id" = "t2_champ2id"))
df.picks <- left_join(df.picks, cont.picks.t2.3, by =c("t1_champ1id" = "t2_champ3id"))
df.picks <- left_join(df.picks, cont.picks.t2.4, by =c("t1_champ1id" = "t2_champ4id"))
df.picks <- left_join(df.picks, cont.picks.t2.5, by =c("t1_champ1id" = "t2_champ5id"))

df.picks$total <- rowSums( df.picks[,2:11] )

remove(cont.picks.t1.1)
remove(cont.picks.t1.2)
remove(cont.picks.t1.3)
remove(cont.picks.t1.4)
remove(cont.picks.t1.5)
remove(cont.picks.t2.1)
remove(cont.picks.t2.2)
remove(cont.picks.t2.3)
remove(cont.picks.t2.4)
remove(cont.picks.t2.5)

df.picks <- df.picks[order(df.picks$total, decreasing = TRUE), ]
df.picks <- df.picks[, -2:-11]
head(df.picks)

# Finalmente, junto con la tabla de data.champs para ponerles nombre...

df.picks <- left_join(df.picks, data.champs, by=c("t1_champ1id" = "id"))
df.picks <- df.picks[, -1]
head(df.picks)


```
Ahora que tenemos todos los picks contados, es hora de hacer un wordcloud para poder verlo visualmente:

```{r wordcloud_picks, warning=FALSE}

set.seed(9998) # Para el mantenimiento del mismo patrón

wordcloud(words = df.picks$name, freq = df.picks$total, min.freq = 3000, random.order=FALSE,
          rot.per=0.5, colors=c("Orange","Purple","Pink", "Red", "Yellow", "Green", "Blue", "Black")
         )

# Ratio del más baneado

print("El porcentaje de pick de Thresh es de: ")
ratio.pick.thresh <- df.picks$total[1]/sum(df.picks$total)
print(ratio.pick.thresh)

```

Exporto el Wordcloud a PDF para tenerlo vectorial...

```{r export_wordcloud_picks}

pdf("../imagenes/wordcloudPicks.pdf")

set.seed(9998) # Para el mantenimiento del mismo patrón

wordcloud(words = df.picks$name, freq = df.picks$total, min.freq = 3000, random.order=FALSE,
          rot.per=0.5, colors=c("Orange","Purple","Pink", "Red", "Yellow", "Green", "Blue", "Black")
         )

dev.off

```


Está muy bien que Thresh y Tristana sean los más elegidos, pero... ¿esto es porque conllevan mayor victoria de partidas?
Vamos a calcularlo:

### ¿Qué camepones conllevan un mayor winrate?

Para esto, lo primero que tenemos que hacer es crear un nuevo dataframe con los campeones que han ganado cada partida:

```{r creacion_dataframe_Campeones_winners}

dataframe.winners.1 <- filter(data.games, winner == "1") 

# En este dataframe, solo me interesan las columnas de los campeones elegidos por el equipo 1, por lo que solo me quedo con ellas:

dataframe.winners.1 <- dataframe.winners.1[, c(12, 15, 18, 21, 24)]
colnames(dataframe.winners.1) <- c("Pick1", "Pick2", "Pick3", "Pick4", "Pick5")

# Hacemos lo mismo con los ganadores del equipo 2

dataframe.winners.2 <- filter(data.games, winner == "2") 

# En este dataframe, solo me interesan las columnas de los campeones elegidos por el equipo 1, por lo que solo me quedo con ellas:

dataframe.winners.2 <- dataframe.winners.2[, c(37, 40, 43, 46, 49)]
colnames(dataframe.winners.2) <- c("Pick1", "Pick2", "Pick3", "Pick4", "Pick5")

# Ahora los juntamos...

dataframe.winners <- rbind(dataframe.winners.1, dataframe.winners.2)

remove(dataframe.winners.1)
remove(dataframe.winners.2)


```

Ahora ya tenemos preparado el dataframe para poder jugar con él.
Procedemos contando el número de ocurrencias que hay de cada campeón, y con esto veremos cual es el campeón que más se repite en este dataframe donde solo están las victorias:

```{r count_occurrences_winners}

# Ahora voy a llevar todas las columnas a una:

dataframe.winners <- data.frame(all = c(dataframe.winners[,"Pick1"],
                                        dataframe.winners[,"Pick2"],
                                        dataframe.winners[,"Pick3"], 
                                        dataframe.winners[,"Pick4"], 
                                        dataframe.winners[,"Pick5"]))

head(dataframe.winners)

dataframe.winners <- left_join(dataframe.winners, data.champs, by=c("all" = "id"))

dataframe.winners <- dataframe.winners[, -1]

head(dataframe.winners)

# Ahora tenemos todo el dataframe en una única columna, donde solo nos queda ordenar y contar el número de ocurrencias:

dataframe.winners <- dataframe.winners[order(dataframe.winners)]
head(dataframe.winners)

# Contamos

cantidad <- as.data.frame(table(dataframe.winners))

cantidad <- cantidad[order(cantidad$Freq, decreasing = TRUE), ]
colnames(cantidad) <- c("name", "freq")
head(cantidad)


```

Como podemos ver, los campeones más elegidos son Tristana y Thresh, que casualmente, como acabamos de probar, son los que tienen más victorias en su haber. También, la tercera con más picks es Vayne, y también es la tercera en cantidad de victorias.

Vamos a calcular el ratio pick-victory:

```{r calculo_ratio_pick_victory}

# Para hacer esto, voy a juntar los dos dataframes en uno solo, juntando por el valor del campeón (nombre), y una vez hecho esto podré restar entre mismas columnas

# No puedo hacer un join normal porque todos mis elementos de texto son factors, por eso lo reconvierto

cantidad <- data.frame(cantidad, stringsAsFactors = FALSE)
colnames(cantidad) <- c("name", "freq_win")

df.picks <- data.frame(df.picks, stringsAsFactors = FALSE)
colnames(df.picks) <- c("total_picks", "name")

dataframe.pick.win <- inner_join(cantidad, df.picks, by="name")

# Ahora que tengo los datos a mano, podemos hacer las divisiones:

dataframe.pick.win <- transform(dataframe.pick.win, ratio = dataframe.pick.win[, 2] / dataframe.pick.win[, 3])

dataframe.pick.win <- dataframe.pick.win[order(dataframe.pick.win$ratio, decreasing = TRUE), ]

head(dataframe.pick.win)

```

Es interesante ver que, a la vista de estos resultados, la gente banea lo que ve mucho, no lo que de verdad gana partidas.
Como podemos observar, Janna, Sona y Yorick son los 3 campeones que más porcentaje de partidas ganan. En cambio, a la hora de escogerlos los vemos en las posiciones 7, 30 y 124.
Respecto a bans, si tantas partidas ganan la masa debería de banearlos, pero se encuentran en las posiciones 5, 91 y 96, por lo que la gente no se da cuenta del peligro de estos campeones en las manos adecuadas.


### ¿El lado rojo (equipo 2) pierde más partidas?

Una de las afirmaciones que corre por la comunidad de League of Legends es la creencia de que el lado rojo, correspondiente con el equipo 2 en nuestro dataset, es el que pierde un mayor número de partidas. Para visualizar esto, lo único que hay que hacer es obtener el winrate del equipo rojo respecto al total de partidas:

```{r winrate_rojo}

columna.wins <- data.games$winner
cantidad.wins <- as.data.frame(table(columna.wins))
colnames(cantidad.wins) <- c("winner", "frequency")
head(cantidad.wins)

# Si calculamos el ratio...

ratio.red <- cantidad.wins[2, 2] / (cantidad.wins[1, 2] + cantidad.wins[2, 2])
ratio.red

ratio.blue <- cantidad.wins[1, 2] / (cantidad.wins[1, 2] + cantidad.wins[2, 2])
ratio.blue

```

Es decir, el grupo que juega en el lado rojo gana el 49,35% de las partidas, mientras que el que juega en el lado azul gana el 50,64%.

Vamos a verlo en forma de gráfica:

```{r barplot_winrate_teams}
ratios_win <- c(ratio.blue, ratio.red)
barplot(ratios_win, main="Victorias por equipo", ylab="Equipo", col = c("Blue", "Red"))

pie(table(data.games$winner), main = "Victorias por equipo", col = c("Blue", "Red"))

```

Lo exportamos a PDF...

```{r export_PDF_winrate}

pdf("../imagenes/Winrate Graphs.pdf")
barplot(ratios_win, main="Victorias por equipo", ylab="Equipo", col = c("Blue", "Red"))
pie(table(data.games$winner), main = "Victorias por equipo", col = c("Blue", "Red"))
dev.off

```


### ¿Quién consigue más primeros objetivos?

Los primeros objetivos son cruciales en la partida, ya que algunos dan extra de oro, pero todos empiezan a decantar la partida a tu favor. Debido a ello, el análisis de si existe alguna diferencia entre los equipos a la hora de conseguir los primeros objetivos se plantea crucial.

Para ello, contaré para cada columna de primeros objetivos qué equipo ha conseguido ser el mejor, y por qué porcentaje, y entonces determinaré si hay alguna ventaja en alguno de los objetivos.


```{r}
# Los datos de esto los tenemos en data.games. Para aclarar, vamos a hacer un dataset específico con los datos de los objetivos...

data.first.objectives <- data.games[, 6:11]

# Es importante remarcar que aquí hay 3 valores: 0 si nadie lo ha conseguido, 1 si lo ha conseguido el equipo azul y 2 si lo ha conseguido el equipo rojo.

head(data.first.objectives)

# Ahora mi objetivo es contar de cada una de las líneas lo que hay, y de aquí sacar conclusiones:

firstblood.qty <- as.data.frame(table(data.first.objectives[, 1]))
firsttower.qty <- as.data.frame(table(data.first.objectives[, 2]))
firstinhib.qty <- as.data.frame(table(data.first.objectives[, 3]))
firstbaron.qty <- as.data.frame(table(data.first.objectives[, 4]))
firstdragon.qty <- as.data.frame(table(data.first.objectives[, 5]))
firstherald.qty <- as.data.frame(table(data.first.objectives[, 6]))

# Ahora lo vemos bien en barplots...

array.firstblood <- c(firstblood.qty[1, 2],firstblood.qty[2, 2], firstblood.qty[3, 2])
barplot(array.firstblood, main="Partidas en las que los equipos hicieron Primera sangre", xlab="Equipo / Ninguno", ylab = "Número de partidas",  
        ylim = c(0,30000), col = c("White", "Blue", "Red"), legend.text=firstblood.qty$Var1)

array.firsttower <- c(firsttower.qty[1, 2],firsttower.qty[2, 2], firsttower.qty[3, 2])
barplot(array.firsttower, main="Partidas en las que los equipos hicieron Primera torre", xlab="Equipo / Ninguno", ylab = "Número de partidas",
        ylim = c(0,30000), col = c("White", "Blue", "Red"), legend.text=firsttower.qty$Var1)

array.firstinhib <- c(firstinhib.qty[1, 2],firstinhib.qty[2, 2], firstinhib.qty[3, 2])
barplot(array.firstinhib, main="Partidas en las que los equipos hicieron primer inhibidor", xlab="Equipo / Ninguno", ylab = "Número de partidas",
        ylim = c(0,30000), col = c("White", "Blue", "Red"), legend.text=firstinhib.qty$Var1)

array.firstbaron <- c(firstbaron.qty[1, 2],firstbaron.qty[2, 2], firstbaron.qty[3, 2])
barplot(array.firstbaron, main="Partidas en las que los equipos hicieron primer barón", xlab="Equipo / Ninguno", ylab = "Número de partidas", 
        ylim = c(0,30000), col = c("White", "Blue", "Red"), legend.text=firstbaron.qty$Var1)

array.firstdragon <- c(firstdragon.qty[1, 2],firstdragon.qty[2, 2], firstdragon.qty[3, 2])
barplot(array.firstdragon, main="Partidas en las que los equipos hicieron primer dragón", xlab="Equipo / Ninguno", ylab = "Número de partidas",
        ylim = c(0,30000), col = c("White", "Blue", "Red"), legend.text=firstdragon.qty$Var1)

array.firstherald <- c(firstherald.qty[1, 2],firstherald.qty[2, 2], firstherald.qty[3, 2])
barplot(array.firstherald, main="Partidas en las que los equipos hicieron el heraldo", xlab="Equipo / Ninguno", ylab = "Número de partidas",
        ylim = c(0,30000), col = c("White", "Blue", "Red"), legend.text=firstherald.qty$Var1)

```

Si ponemos todos estos en orden cronológico a cuando suelen pasar, obtenemos lo siguiente:

```{r cronología_partida_first_objective}

dataframe.firstObjective <- cbind(array.firstblood, array.firsttower, array.firstdragon, array.firstherald, array.firstinhib, array.firstbaron)
colnames(dataframe.firstObjective) <- c('FirstBlood', 'FirstTower', 'FirstDragon', 'FirstHerald', 'FirstInhib', 'FirstBaron')

colours = c("white","blue","red")

barplot(dataframe.firstObjective, main='Cantidad de primer objetivo de cada tipo conseguido por los equipos',ylab='Veces', xlab='Evento',beside = TRUE, 
        col=colours, ylim=c(0,max(dataframe.firstObjective)*1.3))

box()

```

Exportamos a PDF este gráfico...

```{r export_cronologia_partida_first_obj}

pdf("../imagenes/Barplot Cronología Partida FO.pdf")

barplot(dataframe.firstObjective, main='Cantidad de primer objetivo de cada tipo conseguido por los equipos',ylab='Veces', xlab='Evento',beside = TRUE, 
        col=colours, ylim=c(0,max(dataframe.firstObjective)*1.3))

box()

dev.off

```



Como podemos ver en los gráficos, la primera sangre y primera torre suelen caer un poco más del lado del equipo azul, siendo estos elementos que se dan al principio de la partida.

Respecto al primer dragón y el heraldo, que se dan en el medio de la partida, se igualan las tornas.

Sin embargo, con los objetivos de final de partida, como es el primer barón, es el equipo rojo quien lo suele conseguir. En cambio, el equipo azul suele conseguir con un poco más de frecuencia el primer inhibidor.


## Machine Learning


### Preparación datos machine learning

#### Dataset total

Ahora usaremos algoritmos de Machine Learning para ver si somos capaces de predecir quién va a ganar en base a una serie de características.

Para hacer esto, vamos a crear un dataset a partir de data.games solo para lo que va a ser el Machine Learning. En él, dejaré las variables que creo necesarias para la predicción de una partida y así usaremos este dataset, tras un centrado y escalado.

Creación del Dataset:

```{r dataset_ml_creation}

data.games.names <- inner_join(data.games, data.champs, by = c("t1_champ1id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t1_champ2id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t1_champ3id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t1_champ4id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t1_champ5id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t2_champ1id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t2_champ2id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t2_champ3id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t2_champ4id" = "id"))
data.games.names <- inner_join(data.games.names, data.champs, by = c("t2_champ5id" = "id"))

champs.names <- data.games.names[,62:71]
colnames(champs.names) <- c("P1T1", "P2T1", "P3T1", "P4T1", "P5T1", "P1T2", "P2T2", "P3T2", "P4T2", "P5T2")


# Ahora paso todos los campeones a variables binarias. Esto hace que para todas las predicciones no tenga que usar distancias ni categorías entre ellos, lo que me permite que sean más justas.

vectors_champs <- dummy_cols(champs.names)
vectors_champs <- vectors_champs[, -1:-10]

# Ahora lo único que tengo que hacer es crear el dataset final para el machine learning, quitando aquellas variables que no deseo que estén (entre ellas el código de los campeones) y añadiendo esta codificación binaria que acabo de crear.

data.ml <- data.games[, c(-1, -2, -4, -13, -14, -16, -17, -19, -20, -22, -23, -25, -26, -38, -39, -41, -42, -44, -45, -47, -48)]
data.ml <- data.ml[, -9:-13]
data.ml <- data.ml[, -19:-25]

# Ahora hago lo mismo de antes para los nombres pero con los bans. Antes que nada, tengo que añadir None como la elección de ningún campeón para banear en el df de campeones.

df.tonto <- data.frame("None", as.integer(1000))
names(df.tonto) <- c("name", "id")
data.champs <- rbind(data.champs, df.tonto)

data.games[data.games=="-1"]<-1000

data.games.bans <- inner_join(data.games, data.champs, by = c("t1_ban1" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t1_ban2" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t1_ban3" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t1_ban4" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t1_ban5" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t2_ban1" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t2_ban2" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t2_ban3" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t2_ban4" = "id"))
data.games.bans <- inner_join(data.games.bans, data.champs, by = c("t2_ban5" = "id"))

champs.bans.names <- data.games.bans[,62:71]
colnames(champs.bans.names) <- c("B1T1", "B2T1", "B3T1", "B4T1", "B5T1", "B1T2", "B2T2", "B3T2", "B4T2", "B5T2")


vectors_champs.bans <- dummy_cols(champs.bans.names)
vectors_champs.bans <- vectors_champs.bans[, -1:-10]

# Finalmente, hago las últimas transformaciones y adiciones a data.ml para obtener el resultado final

data.ml <- data.ml[, -14:-18]
data.ml <- data.ml[, -19:-23]

data.ml <- cbind(data.ml, vectors_champs, vectors_champs.bans)

# Finalmente,hago una segunda matriz sin el resultado, que será la que centre y escale:

data.ml.centscal <- data.ml[, -2]

```


Ahora hacemos un centrado y escalado de los datos para evitar distorsionar la predicción:

```{r centrado_escalado}

preObjeto <- preProcess(data.ml.centscal, method=c("center", "scale"))  # Quiero hacer un centrado y escalado
data.ml.centscal <- predict(preObjeto, data.ml.centscal)

```

Estos archivos son grandes, veamos su tamaño:

```{r size_tras_centrado_escalado}

object_size(data.ml)
object_size(data.ml.centscal)

```

```{r PCA_Calculations_ml}

resultado.pca.ml <- PCA(data.ml.centscal, graph = FALSE)

#Con la siguiente línea podemos ver que podemos hacer con esto calculado
print(resultado.pca.ml)

```

Nos interesa ver los eigenvalues, que son los que presentarán la cantidad de varianza que aportan las variables:

```{r table_eigenvalues_PCA_ml}

eigenvalues.PCA.ml <- resultado.pca.ml$eig
head(eigenvalues.PCA.ml)

```
Como se puede comprobar, de las 24 variables (componentes) que tenemos, la mitad de la varianza la conseguimos con aproximadamente 5 variables.
También se puede ver que a parti de las 17 variables prácticamente no hay un aumento de la varianza.
En el caso de un problema grande, sería interesante la eliminación de algunas de las variables, para dejar un dataset más pequeño con el que poder trabajar. En nuestro caso, nuestro problema es pequeño, y además las variables están escogidas a mano, por lo que no haré una reducción del dataset.

Ahora, para completar este apartado de PCA, lo que voy a hacer es sacar la gráfica de la varianza acumulada con los valores anteriores:

```{r PCA_eigenvalues_graph_ml}

plotPCA.ml <- fviz_screeplot(resultado.pca.ml, ncp=60)
plot(plotPCA.ml)

```

Exportamos a PDF...

```{r export_PDF_total}

pdf("../imagenes/PCATotal.pdf")
plot(plotPCA.ml)
dev.off

```


Como vemos, todas las dimensiones van aportando su "granito de arena", pero ninguna de ellas (según estamos viendo en las 60 primeras) deja de aportar un poco.

Si vamos al dataframe generado en eigenvalues.PCA.ml, vemos que hasta que no llegamos a las 2000 componentes principales no obtenemos al menos un 80% de explicación, mientras que hasta que no llegamos a unas pocas dimensiones del final no obtenemos la explicación completa. Por ello, no reduciré las dimensiones del dataframe, y trabajaremos con él a pesar de que sea más lento y pesado.

#### Dataset campeones

A partir del dataset total, voy a hacer un dataset solo con los campeones (ya codificados), de tal manera que se pueda predecir también solo por ellos:

```{r creacion_dataset_ml_solo_camps}

data.ml.campeones <- data.ml[, 19:2788]

#matriz.sparse.campeones <- Matrix(data.ml.campeones, sparse = T)

```

Ahora, al igual que antes, calculamos el PCA:

```{r PCA_Calculations_campeones_ml}

resultado.pca.campeones.ml <- PCA(data.ml.campeones, graph = FALSE)

#Con la siguiente línea podemos ver que podemos hacer con esto calculado
print(resultado.pca.campeones.ml)

```

Nos interesa ver los eigenvalues, que son los que presentarán la cantidad de varianza que aportan las variables:

```{r table_eigenvalues_PCA_ml_campeones}

eigenvalues.PCA.campeones.ml <- resultado.pca.campeones.ml$eig
head(eigenvalues.PCA.campeones.ml)

```

Ahora, para completar este apartado de PCA, lo que voy a hacer es sacar la gráfica de la varianza acumulada con los valores anteriores:

```{r PCA_eigenvalues_graph_ml_campeones}

plotPCA.campeones.ml <- fviz_screeplot(resultado.pca.campeones.ml, ncp=60)
plot(plotPCA.campeones.ml)

```

Exportamos a PDF...

```{r export_PDF_mlCampeones}

pdf("../imagenes/PCACampones.pdf")
plot(plotPCA.campeones.ml)
dev.off

```


#### Dataset datos equipos

A partir del dataset total, voy a hacer un dataset solo con las estadísticas de los equipos, de tal manera que se pueda predecir también solo por ellos, creando un dataset más pequeño. Con este dataset corroboraremos que no hacen falta los campeones para predecir el ganador de una partida, sino que con las estadísticas vale:

```{r creacion_dataset_ml_solo_stats}

data.ml.stats.centscal <- data.ml[, 1:18]
data.ml.stats.centscal <- data.ml.stats.centscal[, -2] #Quitamos el ganador

preObjeto.stats <- preProcess(data.ml.stats.centscal, method=c("center", "scale"))  # Quiero hacer un centrado y escalado
data.ml.stats.centscal <- predict(preObjeto.stats, data.ml.stats.centscal)

```

Ahora, al igual que antes, calculamos el PCA:

```{r PCA_Calculations_stats_ml}

resultado.pca.stats.ml <- PCA(data.ml.stats.centscal, graph = FALSE)

#Con la siguiente línea podemos ver que podemos hacer con esto calculado
print(resultado.pca.stats.ml)

```

Nos interesa ver los eigenvalues, que son los que presentarán la cantidad de varianza que aportan las variables:

```{r table_eigenvalues_PCA_ml_stats}

eigenvalues.PCA.stats.ml <- resultado.pca.stats.ml$eig
head(eigenvalues.PCA.stats.ml)

```

Ahora, para completar este apartado de PCA, lo que voy a hacer es sacar la gráfica de la varianza acumulada con los valores anteriores:

```{r PCA_eigenvalues_graph_ml_stats}

plotPCA.stats.ml <- fviz_screeplot(resultado.pca.stats.ml, ncp=60)
plot(plotPCA.stats.ml)

```

Exportamos a PDF:

```{r export_PDF_ml.stats}

pdf("../imagenes/PCAstatsML.pdf")
plot(plotPCA.stats.ml)
dev.off

```


### Algoritmos Supervisados

Pasamos ahora a una revisión / uso de algoritmos supervisados:

#### Perceptrón Multicapa

El algoritmo supervisado por el que siempre se debe de empezar es el perceptrón multicapa. Con este algoritmo de clasificación voy a intentar predecir el resultado de la partida.
Este algoritmo se basa en una red neuronal con una capa intermedia (en este caso), mediante la cual podemos procesar datos más complejos que con un perceptrón monocapa.
Con este algoritmo comprobaremos si las partidas ganadas por unos y por otros son linealmente separables.

Ahora vamos a importar la librería nnet, que nos sirve para hacer perceptrones 

Ahora lo que hago es coger un conjunto muy grande de los datos para hacer el entrenamiento

```{r creación_conjunto_entrenamiento}

conjuntoEntrenamiento <- sample(1:nrow(data.ml.stats.centscal), 45000)

```


Creo una tabla para guardar los resultados de todos los tests del perceptrón:

```{r table_results_perceptron}

resultados.perceptron <- data.frame(stringsAsFactors=FALSE) 

```



###############################################################
 1 NEURONA ####################################################
###############################################################


Lo que voy a hacer ahora es entrenar la red neuronal con diferente cantidad de neuronas,y voy a ir comparando el resultado...

SIN SOFTMAX #############################

```{r 1_neurona}

# Ahora creamos un dataframe para guardar los resultados de este bucle
  
  dataframe.resultados.1neu <- data.frame(Ent_1neu=numeric(),
                                          Test_1neu=numeric())


for (i in 1:10)
{
  
  partidas.1neu <- nnet( data.ml.stats.centscal[conjuntoEntrenamiento, ], class.ind( data.ml[conjuntoEntrenamiento, 2] ) , size=1, MaxNWts=10000 )
  
  #Una vez que lo tengo entrenado, lo que voy a hacer es calcular el error tanto en el entrenamiento como en el test de cada uno
  
  partidas.prediccion.1neu <- predict( partidas.1neu, data.ml.stats.centscal[conjuntoEntrenamiento, ], type="raw" )
  head(partidas.prediccion.1neu) # Vemos las probabilidades de pertenencia de cada valor
  
  # Ahora que los tengo todos entrenados, Determinamos cual es la máxima, es decir, la clase a la que hay que asignar los objetos
  
  partidas.prediccion.1neu.class <- apply( partidas.prediccion.1neu, MARGIN=1, FUN='which.is.max')
  
  #Calculo el acierto
  
  acierto_ent_1neu<- sum( diag( table( partidas.prediccion.1neu.class, data.ml[conjuntoEntrenamiento, 2] ) ) )/length(conjuntoEntrenamiento)
  
  ###### TEST
  
  
  partidas.prediccion.test.1neu <- predict( partidas.1neu, data.ml.stats.centscal[-conjuntoEntrenamiento, ], type="raw" )

  partidas.prediccion.test.1neu.class <- apply( partidas.prediccion.test.1neu, MARGIN=1, FUN='which.is.max')

  table( partidas.prediccion.test.1neu.class , data.ml[-conjuntoEntrenamiento, 2] )
  
  acierto_test_1neu <- sum( diag( table( partidas.prediccion.test.1neu.class, data.ml[-conjuntoEntrenamiento, 2] ) ) )/(nrow(data.ml.stats.centscal) - length(conjuntoEntrenamiento))

    
  dataframe.pasada <- data.frame(Ent_1neu = acierto_ent_1neu,
                                 Test_1neu= acierto_test_1neu)
  
  dataframe.resultados.1neu <- rbind(dataframe.resultados.1neu, dataframe.pasada)
  
} 


```

Ahora le vamos a añadir softmax, a ver si mejoramos...


CON SOFTMAX #############################

```{r 1_neurona_softmax}


  dataframe.resultados.1neu.soft <- data.frame(Ent_1neu_soft=numeric(),
                                               Test_1neu_soft=numeric())

for (i in 1:10)
{
  
  partidas.1neu.soft <- nnet( data.ml.stats.centscal[conjuntoEntrenamiento, ], class.ind( data.ml[conjuntoEntrenamiento, 2] ) , size=1, MaxNWts=10000, softmax = T )
  
  #Una vez que lo tengo entrenado, lo que voy a hacer es calcular el error tanto en el entrenamiento como en el test de cada uno
  
  partidas.prediccion.1neu.soft <- predict( partidas.1neu.soft, data.ml.stats.centscal[conjuntoEntrenamiento, ], type="raw" )
  head(partidas.prediccion.1neu.soft) # Vemos las probabilidades de pertenencia de cada valor
  
  # Ahora que los tengo todos entrenados, Determinamos cual es la máxima, es decir, la clase a la que hay que asignar los objetos
  
  partidas.prediccion.1neu.class.soft <- apply( partidas.prediccion.1neu.soft, MARGIN=1, FUN='which.is.max')
  
  #Calculo el acierto
  
  acierto_ent_1neu.soft <- sum( diag( table( partidas.prediccion.1neu.class.soft, data.ml[conjuntoEntrenamiento, 2] ) ) )/length(conjuntoEntrenamiento)
  
  ###### TEST
  
  
  partidas.prediccion.test.1neu.soft <- predict( partidas.1neu.soft, data.ml.stats.centscal[-conjuntoEntrenamiento, ], type="raw" )

  partidas.prediccion.test.1neu.class.soft <- apply( partidas.prediccion.test.1neu.soft, MARGIN=1, FUN='which.is.max')

  table( partidas.prediccion.test.1neu.class.soft , data.ml[-conjuntoEntrenamiento, 2] )
  
  acierto_test_1neu.soft <- sum( diag( table( partidas.prediccion.test.1neu.class.soft, data.ml[-conjuntoEntrenamiento, 2] ) ) )/(nrow(data.ml.stats.centscal) - length(conjuntoEntrenamiento))

    
  dataframe.pasada <- data.frame(Ent_1neu_soft = acierto_ent_1neu.soft,
                                 Test_1neu_soft= acierto_test_1neu.soft)
  
  dataframe.resultados.1neu.soft <- rbind(dataframe.resultados.1neu.soft, dataframe.pasada)
  
} 

```


###############################################################
 2 NEURONAS ###################################################
###############################################################


SIN SOFTMAX #############################

```{r 2_neuronas}

dataframe.resultados.2neu <- data.frame(Ent_2neu=numeric(),
                                        Test_2neu=numeric())


for (i in 1:10)
{
  
  partidas.2neu <- nnet( data.ml.stats.centscal[conjuntoEntrenamiento, ], class.ind( data.ml[conjuntoEntrenamiento, 2] ) , size=2, MaxNWts=10000 )
  
  #Una vez que lo tengo entrenado, lo que voy a hacer es calcular el error tanto en el entrenamiento como en el test de cada uno
  
  partidas.prediccion.2neu <- predict( partidas.2neu, data.ml.stats.centscal[conjuntoEntrenamiento, ], type="raw" )
  head(partidas.prediccion.2neu) # Vemos las probabilidades de pertenencia de cada valor
  
  # Ahora que los tengo todos entrenados, Determinamos cual es la máxima, es decir, la clase a la que hay que asignar los objetos
  
  partidas.prediccion.2neu.class <- apply( partidas.prediccion.2neu, MARGIN=1, FUN='which.is.max')
  
  #Calculo el acierto
  
  acierto_ent_2neu<- sum( diag( table( partidas.prediccion.2neu.class, data.ml[conjuntoEntrenamiento, 2] ) ) )/length(conjuntoEntrenamiento)
  
  ###### TEST
  
  
  partidas.prediccion.test.2neu <- predict( partidas.2neu, data.ml.stats.centscal[-conjuntoEntrenamiento, ], type="raw" )

  partidas.prediccion.test.2neu.class <- apply( partidas.prediccion.test.2neu, MARGIN=1, FUN='which.is.max')

  table( partidas.prediccion.test.2neu.class , data.ml[-conjuntoEntrenamiento, 2] )
  
  acierto_test_2neu <- sum( diag( table( partidas.prediccion.test.2neu.class, data.ml[-conjuntoEntrenamiento, 2] ) ) )/(nrow(data.ml.stats.centscal) - length(conjuntoEntrenamiento))

    
  dataframe.pasada <- data.frame(Ent_2neu = acierto_ent_2neu,
                                 Test_2neu= acierto_test_2neu)
  
  dataframe.resultados.2neu <- rbind(dataframe.resultados.2neu, dataframe.pasada)
  
} 

```

Ahora le vamos a añadir softmax, a ver si mejoramos...


CON SOFTMAX #############################

```{r 2_neuronas_softmax}

dataframe.resultados.2neu.soft <- data.frame(Ent_2neu_soft=numeric(),
                                             Test_2neu_soft=numeric())

for (i in 1:10)
{
  
  partidas.2neu.soft <- nnet( data.ml.stats.centscal[conjuntoEntrenamiento, ], class.ind( data.ml[conjuntoEntrenamiento, 2] ) , size=2, MaxNWts=10000, softmax = T )
  
  #Una vez que lo tengo entrenado, lo que voy a hacer es calcular el error tanto en el entrenamiento como en el test de cada uno
  
  partidas.prediccion.2neu.soft <- predict( partidas.2neu.soft, data.ml.stats.centscal[conjuntoEntrenamiento, ], type="raw" )
  head(partidas.prediccion.2neu.soft) # Vemos las probabilidades de pertenencia de cada valor
  
  # Ahora que los tengo todos entrenados, Determinamos cual es la máxima, es decir, la clase a la que hay que asignar los objetos
  
  partidas.prediccion.2neu.class.soft <- apply( partidas.prediccion.2neu.soft, MARGIN=1, FUN='which.is.max')
  
  #Calculo el acierto
  
  acierto_ent_2neu.soft <- sum( diag( table( partidas.prediccion.2neu.class.soft, data.ml[conjuntoEntrenamiento, 2] ) ) )/length(conjuntoEntrenamiento)
  
  ###### TEST
  
  
  partidas.prediccion.test.2neu.soft <- predict( partidas.2neu.soft, data.ml.stats.centscal[-conjuntoEntrenamiento, ], type="raw" )

  partidas.prediccion.test.2neu.class.soft <- apply( partidas.prediccion.test.2neu.soft, MARGIN=1, FUN='which.is.max')

  table( partidas.prediccion.test.2neu.class.soft , data.ml[-conjuntoEntrenamiento, 2] )
  
  acierto_test_2neu.soft <- sum( diag( table( partidas.prediccion.test.2neu.class.soft, data.ml[-conjuntoEntrenamiento, 2] ) ) )/(nrow(data.ml.stats.centscal) - length(conjuntoEntrenamiento))

    
  dataframe.pasada <- data.frame(Ent_2neu_soft = acierto_ent_2neu.soft,
                                 Test_2neu_soft= acierto_test_2neu.soft)
  
  dataframe.resultados.2neu.soft <- rbind(dataframe.resultados.2neu.soft, dataframe.pasada)
  
} 

```




###############################################################
 3 NEURONAS ###################################################
###############################################################


SIN SOFTMAX #############################

```{r 3_neuronas}

dataframe.resultados.3neu <- data.frame(Ent_3neu=numeric(),
                                        Test_3neu=numeric())


for (i in 1:10)
{
  
  partidas.3neu <- nnet( data.ml.stats.centscal[conjuntoEntrenamiento, ], class.ind( data.ml[conjuntoEntrenamiento, 2] ) , size=3, MaxNWts=10000 )
  
  #Una vez que lo tengo entrenado, lo que voy a hacer es calcular el error tanto en el entrenamiento como en el test de cada uno
  
  partidas.prediccion.3neu <- predict( partidas.2neu, data.ml.stats.centscal[conjuntoEntrenamiento, ], type="raw" )
  head(partidas.prediccion.3neu) # Vemos las probabilidades de pertenencia de cada valor
  
  # Ahora que los tengo todos entrenados, Determinamos cual es la máxima, es decir, la clase a la que hay que asignar los objetos
  
  partidas.prediccion.3neu.class <- apply( partidas.prediccion.3neu, MARGIN=1, FUN='which.is.max')
  
  #Calculo el acierto
  
  acierto_ent_3neu<- sum( diag( table( partidas.prediccion.3neu.class, data.ml[conjuntoEntrenamiento, 2] ) ) )/length(conjuntoEntrenamiento)
  
  ###### TEST
  
  
  partidas.prediccion.test.3neu <- predict( partidas.3neu, data.ml.stats.centscal[-conjuntoEntrenamiento, ], type="raw" )

  partidas.prediccion.test.3neu.class <- apply( partidas.prediccion.test.3neu, MARGIN=1, FUN='which.is.max')

  table( partidas.prediccion.test.3neu.class , data.ml[-conjuntoEntrenamiento, 2] )
  
  acierto_test_3neu <- sum( diag( table( partidas.prediccion.test.3neu.class, data.ml[-conjuntoEntrenamiento, 2] ) ) )/(nrow(data.ml.stats.centscal) - length(conjuntoEntrenamiento))

    
  dataframe.pasada <- data.frame(Ent_3neu = acierto_ent_3neu,
                                 Test_3neu= acierto_test_3neu)
  
  dataframe.resultados.3neu <- rbind(dataframe.resultados.3neu, dataframe.pasada)
  
} 

```

Ahora le vamos a añadir softmax, a ver si mejoramos...


CON SOFTMAX #############################

```{r 3_neuronas_softmax}

dataframe.resultados.3neu.soft <- data.frame(Ent_3neu_soft=numeric(),
                                             Test_3neu_soft=numeric())

for (i in 1:10)
{
  
  partidas.3neu.soft <- nnet( data.ml.stats.centscal[conjuntoEntrenamiento, ], class.ind( data.ml[conjuntoEntrenamiento, 2] ) , size=3, MaxNWts=10000, softmax = T )
  
  #Una vez que lo tengo entrenado, lo que voy a hacer es calcular el error tanto en el entrenamiento como en el test de cada uno
  
  partidas.prediccion.3neu.soft <- predict( partidas.3neu.soft, data.ml.stats.centscal[conjuntoEntrenamiento, ], type="raw" )
  head(partidas.prediccion.3neu.soft) # Vemos las probabilidades de pertenencia de cada valor
  
  # Ahora que los tengo todos entrenados, Determinamos cual es la máxima, es decir, la clase a la que hay que asignar los objetos
  
  partidas.prediccion.3neu.class.soft <- apply( partidas.prediccion.3neu.soft, MARGIN=1, FUN='which.is.max')
  
  #Calculo el acierto
  
  acierto_ent_3neu.soft <- sum( diag( table( partidas.prediccion.3neu.class.soft, data.ml[conjuntoEntrenamiento, 2] ) ) )/length(conjuntoEntrenamiento)
  
  ###### TEST
  
  
  partidas.prediccion.test.3neu.soft <- predict( partidas.3neu.soft, data.ml.stats.centscal[-conjuntoEntrenamiento, ], type="raw" )

  partidas.prediccion.test.3neu.class.soft <- apply( partidas.prediccion.test.3neu.soft, MARGIN=1, FUN='which.is.max')

  table( partidas.prediccion.test.3neu.class.soft , data.ml[-conjuntoEntrenamiento, 2] )
  
  acierto_test_3neu.soft <- sum( diag( table( partidas.prediccion.test.3neu.class.soft, data.ml[-conjuntoEntrenamiento, 2] ) ) )/(nrow(data.ml.stats.centscal) - length(conjuntoEntrenamiento))

    
  dataframe.pasada <- data.frame(Ent_3neu_soft = acierto_ent_3neu.soft,
                                 Test_3neu_soft= acierto_test_3neu.soft)
  
  dataframe.resultados.3neu.soft <- rbind(dataframe.resultados.3neu.soft, dataframe.pasada)
  
} 

```



Ahora juntamos todos los resultados:

```{r join_results_perceptron}

dataframe.resultados.perceptron.stats <- cbind(dataframe.resultados.1neu, 
                                              dataframe.resultados.1neu.soft, 
                                              dataframe.resultados.2neu,
                                              dataframe.resultados.2neu.soft,
                                              dataframe.resultados.3neu,
                                              dataframe.resultados.3neu.soft)

remove(dataframe.resultados.1neu)
remove(dataframe.resultados.1neu.soft)
remove(dataframe.resultados.2neu)
remove(dataframe.resultados.2neu.soft)
remove(dataframe.resultados.3neu)
remove(dataframe.resultados.3neu.soft)

```

Ahora, con estos resultados en el dataframe, vamos a ver los mejores resultados que he obtenido con cada red neuronal:

```{r analisis_resultados_nnet}

head(dataframe.resultados.perceptron.stats[order(dataframe.resultados.perceptron.stats$Test_1neu, decreasing = TRUE), 1:2])
head(dataframe.resultados.perceptron.stats[order(dataframe.resultados.perceptron.stats$Test_1neu_soft, decreasing = TRUE), 3:4])
head(dataframe.resultados.perceptron.stats[order(dataframe.resultados.perceptron.stats$Test_2neu, decreasing = TRUE), 5:6])
head(dataframe.resultados.perceptron.stats[order(dataframe.resultados.perceptron.stats$Test_2neu_soft, decreasing = TRUE), 7:8])
head(dataframe.resultados.perceptron.stats[order(dataframe.resultados.perceptron.stats$Test_3neu, decreasing = TRUE), 9:10])
head(dataframe.resultados.perceptron.stats[order(dataframe.resultados.perceptron.stats$Test_3neu_soft, decreasing = TRUE), 11:12])

```

Como podemos ver, el mejor resultado lo obtenemos con 3 neuronas y softmax, pero no difiere prácticamente nada con 1 neurona o 2 neuronas. De este modo, ante la igualdad de condiciones, la mejor red es la más simple, y por lo tanto la de 1 neurona.


#### KNN

K - Nearest Neighbours es otro algoritmo de clasificación muy utilizado. Se basa en la posición del nodo que se está analizando con los K nodos más cercanos mediante distancia euclídea. De este modo, calcula la similitud e indentifica a un nodo como de un grupo o de otro.

La teoría dice que para K-NN, el mejor número a escoger es la raíz cuadrada del total de observaciones que tenemos. Lo calculamos:

```{r sqrt_dataframe.ml.centscal_size}

k <- round(sqrt(nrow(data.ml.stats.centscal)), 0) 

```

Ahora creamos los grupos: 

```{r creacion_grupos_knn}

conjuntoEntrenamiento <- data.ml.stats.centscal[1:45000, ]
conjuntoTest <- data.ml.stats.centscal[45001 : nrow(data.ml.stats.centscal), ] # Utilizo por supuesto la matriz de centrado y escalado

etiquetasEntrenamiento <- data.ml[1:45000, 2]
etiquetasTest <- data.ml[45001:nrow(data.ml.stats.centscal), 2] 

```


Ahora lo que vamos a hacer es calcular para diferentes K's el resultado que obtenemos, para ver qué tal clasifica:


###### K = 227 

```{r knn_227}

prediccion.knn.227 <- knn(train = conjuntoEntrenamiento, 
                          test = conjuntoTest, 
                          cl = etiquetasEntrenamiento,
                          k = 227) 
head(prediccion.knn.227)

```

Sacamos crosstable:

```{r crosstable_227}

CrossTable(x = etiquetasTest ,
           y = prediccion.knn.227, 
           prop.chisq = FALSE) 
```


Ahora voy a hacer lo mismo con 150 y con 350, para ver las diferencias que puede haber con la predicción:

###### K = 150 

```{r knn_150}

prediccion.knn.150 <- knn(train = conjuntoEntrenamiento, 
                          test = conjuntoTest, 
                          cl = etiquetasEntrenamiento,
                          prob = TRUE,
                          k = 150) 
head(prediccion.knn.150)

```

Sacamos crosstable:

```{r crosstable_150}

CrossTable(x = etiquetasTest ,
           y = prediccion.knn.150, 
           prop.chisq = FALSE) 
```



###### K = 350 

```{r knn_350}

prediccion.knn.350 <- knn(train = conjuntoEntrenamiento, 
                          test = conjuntoTest, 
                          cl = etiquetasEntrenamiento,
                          prob = TRUE,
                          k = 350)
head(prediccion.knn.350)

```

Sacamos crosstable:

```{r crosstable_350}

CrossTable(x = etiquetasTest ,
           y = prediccion.knn.350, 
           prop.chisq = FALSE)
```


#### Random Forest

Random Forest es otro algoritmo supervisado que se basa en la creación de árboles de decisión, en los cuales se hacen preguntas y según la contestación obtenemos un resultado u otro. Finalmente, todos los bosques que se forman llegan a un acuerdo y se pone la decisión final.

Para el random forest no se necesita por su naturaleza un centrado y escalado anterior, de tal manera que directamente procedo con la parte de estadísticas del dataframe original:

```{r randomforest_firstTry}

data.ml.rf <-  data.ml[, 1:18]
data.ml.rf <- data.ml.rf[, -2] # Me quedo solo con la parte de stats y sin el ganador

model <- randomForest(as.factor(data.ml[, 2]) ~ ., data = data.ml.rf, importance = TRUE, ntree = 300)
model

```
Aquí podemos ver la matriz de confusión, de la que obtenemos también el fallo por clases.

El Out-Of-Bag es un método de estimación de error que se usa en algunos algoritmos como Random Forest, y usa el modelo de Bagging para hacer muestras de submuestras usadas para el entrenamiento.
El OOB es el error de predidcción medio de cada una de las muestras de entrenamiento.

Bagging es un meta-algoritmo usado para aumentar la estabilidad y precisión de algoritmos de Machine Learning de clasificación y regresión.

Ahora obtenemos el número de árboles que necesitamos realmente, y la importancia de las variables en este modelo:

```{r importance_graphs_RF_firstTry}

plot(model, main="Random Forest - Solo Stats")

varImpPlot(model, main = "Random Forest (Stats) - MDA y Gini") # Gracias a importance = true 

```

Lo exportamos a PDF...

```{r export_PDF_RF_FT}

pdf("../imagenes/RandomForest_FT.pdf")
plot(model, main="Random Forest - Solo Stats")
varImpPlot(model, main = "Random Forest (Stats) - MDA y Gini")
dev.off

```

Vamos a interpretar estos datos del modelo:

+ MeanDecreaseAccuracy se refiere al decremento de la exactitud del modelo si se permutan los valores en cada característica. En otras palabras, MDA nos muestra la media de valores que se clasificarían mal si se quitara esa característica de la predicción. Los valores que nos da MDA son la media de las variables que no se clasificarían bien en caso de quitar esas variables del entrenamiento del modelo. En nuestro caso, game duration, los inhibidores y las torres son lo que más información le está aportando al modelo.

+ MeanDecreaseGini se refiere a la medida de la ganancia media de pureza mediante la división de cierta variable. Cuanto más importante sea la variable, habrá un mayor descenso en el Gini. La importancia de este está íntimamente relacionada a la función de decisión local, que Random Forest usa para seleccionar cual es la mejor separación. Como vemos, las torres y los inhibidores vuelven a ser cruciales para determinar quién es el ganador de la partida.


Ahora lo voy a hacer con 10 fold X Validation:

```{r randomforest_10F-XValidation}

result <- rfcv(data.ml.rf, as.factor(data.ml[, 2]), cv.fold=10) 
head(result)

```


#### SVM Kernel Lineal

SVM es una técnica supervisada que es muy robusta frente a la dimensionalidad. En este caso, nuestro problema no tiene una dimensión excesiva, pero Vamos a usar esta técnica para ver qué resultados nos arroja.
En este caso, con Kernel Lineal:


```{r creacion_modelo_svm}

modelo.svm <- svm(data.ml.stats.centscal, as.factor(data.ml[, 2]), kernel = "linear") # Al poner los grupos como factor, estoy consiguiendo que no sean continuos para el modelo, sino "discretos", ya que los factor no son valores que puedan ser continuos. Con esto consigo una clasificación.
summary(modelo.svm)
 
```


Ahora que tenemos creado este primer modelo, toca predecir:

```{r prediccion_svm}

prediccion <- predict(modelo.svm, data.ml.stats.centscal)
head(prediccion)
 
```

Ahora que hemos predicho, tenemos que sacar la matriz de confusión:

```{r matriz_confusion_svm_Acierto}

matriz.conf <- table(prediccion, data.ml[, 2])
matriz.conf

sum(diag(matriz.conf))/nrow(data.ml) 

```


#### SVM Kernel Radial

Ahora vamos a probar SVM pero con Kernel Radial:

```{r creacion_modelo_svm_RBF}

modelo_svm.radial <- svm(data.ml.stats.centscal, as.factor(data.ml[, 2]), kernel="radial")
summary(modelo_svm.radial) 

```

Aquí tenemos una C-Classification (necesaria para clasificar), con Kernel esta vez radial.

Ahora que tenemos creado este segundo modelo, toca predecir:

```{r prediccion_modelo_svm_RBF}

prediccion.radial <- predict(modelo_svm.radial, data.ml.stats.centscal)
head(prediccion.radial)

```

Ahora que hemos predicho, tenemos que sacar la matriz de confusión:

```{r matriz_confusion_svm_RBF_Acierto}

matriz.conf.radial <- table(prediccion.radial, data.ml[, 2])
matriz.conf.radial
sum(diag(matriz.conf.radial))/nrow(data.ml) 

```


#### Epílogo Modelos Supervisados

Como hemos visto, solo con la parte de estadísticas podemos obtener una predicción de los resultados bastante acertada.
Los otros dos dataframes que he creado (champions y total) tendríamos que probarlos ante los mismos métodos, pero el problema es que son demasiado grandes como para ejecutarlos en un ordenador de una manera medianamente rápida (según mis cálculos, en mi portátil son más de 2 días de computación contínua).  De este modo, queda aquí indicado que la prueba de ellos (especialmente el de sólo campeones) sería una buena muestra de ver si se puede predecir el resultado de la partida sin las estadísticas principales.

### Algoritmos no supervisados


#### K-Means

La técnica de clasificación y clustering no supervisada más utilizada es K-Means. K es el número de grupos que queremos formar.
Se basa en clustering circular o elíptico, lo cual lo limita, pero tendremos que ver qué resultados nos arroja.

Este método, como lo estoy haciendo de las 51490 partidas, puede tardar un poco en procesar:

```{r kmeans}

datos.kmeans <- data.ml[1:nrow(data.ml), ]

clusters <- kmeans(datos.kmeans, centers = 2) #Dos centros, uno por vencedor

# Ahora sacamos las plots

#Esta representación es sobre los dos ejes principales (componentes) que más explicación dan
clusplot(datos.kmeans, clusters$cluster, color = T, main = "Representación de las 51490 partidas en 2D - Función Clusplot", xlab = "Componente 1", ylab = "Componente 2")

#Esta representación es con componentes discriminantes, que consisten en las dos dimensiones donde la representación de los datos es más linealmente separable respecto a la predicción de los grupos que ha hecho kmeans

plotcluster(datos.kmeans, clusters$cluster)

```

Ahora lo exportamos a PDF

```{r export_pdf_clusters_kmeans}

pdf("../imagenes/resultados_kmeans.pdf")

clusplot(datos.kmeans, clusters$cluster, color = T, main = "Representación de las 51490 partidas en 2D - Función Clusplot", xlab = "Componente 1", ylab = "Componente 2")

plotcluster(datos.kmeans, clusters$cluster)

dev.off

```


Como podemos ver, los datos de ninguna manera son perfectamente separables, sino que las partidas que gana el equipo 1 se centran más a la izquierda en esta componente discriminante que forma x, y las del dos se centran más a la derecha. Como podemos ver, está bastante difuminada la frontera.


#### Cluster Jerárquico

En este caso, el cluster lo haré con un número reducido de partidas, ya que si no el cluster no se verá demasiado bien:

```{r cluster_jerarquico}

#Usamos la matriz de centrado y escalado para que cada coordenada represente el mismo grado de diferencia

d <- dist(data.ml.stats.centscal[1:60, ], method = "euclidean")

cluster.jerarquico <- hclust(d, method = "complete" )

plot(cluster.jerarquico, cex = 0.5, hang = -1, main="Dendrograma 75 primeras partidas")

```

Exportamos a PDF...

```{r export_PDF_clusterJerarquico}

pdf("../imagenes/clusterJerárquico.pdf")

plot(cluster.jerarquico, cex = 0.5, hang = -1, main="Dendrograma 60 primeras partidas")

dev.off()

```


## Rule Mining - Reglas

Podemos obtener una serie de reglas para confirmar las afirmaciones que he hecho sobre los datos, y obtener nueva información:

### Reglas respecto a First Blood

```{r obtener_reglas_firstblood}

#Lo primero que hago es obtener el dataframe ya creado, y eliminar todas las columnas indeseadas:

data.reglas <- data.games.names[, -12:-26]
data.reglas <- data.reglas[, -42:-46]
data.reglas <- data.reglas[, -17:-36]
data.reglas <- data.reglas[, c(-1, -2, -4)]
data.reglas <- data.reglas[, c(-19:-28)]

data.reglas.fbl = data.reglas

#Estas reglas me impiden convertir a factor los elementos categóricos, por lo que lo mantengo en integer. Solo puedo cambiar el elemento que usaré como clase:

data.reglas.fbl$firstBlood <- as.factor(data.reglas.fbl$firstBlood)

#Finalmente sacamos las reglas

part_firstblood <- PART(firstBlood~., data = data.reglas.fbl)
oneR_firstBlood <- OneR(firstBlood~., data = data.reglas.fbl)
jrip_firstBlood <- JRip(firstBlood~., data = data.reglas.fbl)

```


### Reglas Respecto a First Inhibitor

```{r obtener_reglas_firstinhibitor}

data.reglas.fin = data.reglas

data.reglas.fin$firstInhibitor <- as.factor(data.reglas.fin$firstInhibitor)

part_firstInhib <- PART(firstInhibitor~., data = data.reglas.fin)
oneR_firstInhib <- OneR(firstInhibitor~., data = data.reglas.fin)
jrip_firstInhib <- JRip(firstInhibitor~., data = data.reglas.fin)

```

### Reglas respecto al Ganador

```{r obtener_reglas_winner}

data.reglas.win = data.reglas

data.reglas.win$winner <- as.factor(data.reglas.win$winner)

part_winner <- PART(winner~., data = data.reglas.win)
oneR_winner <- OneR(winner~., data = data.reglas.win)
jrip_winner <- JRip(winner~., data = data.reglas.win)

```


